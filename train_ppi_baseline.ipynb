{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_ppi_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jedhouas/Digraph/blob/master/train_ppi_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChS6d0nWBwYt",
        "colab_type": "code",
        "outputId": "dafa7452-6793-4b6b-a525-d5f396b0dd00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "# for CPU \n",
        "!pip  install dgl\n",
        "\n",
        "#For GPU \n",
        "#!pip install dgl-cu101"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/3a/34fcdd3ec13cc945db277f87ca8ea3bf320fba8a6c04dc675f257869f45b/dgl-0.4.2-cp36-cp36m-manylinux1_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.17.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.1)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7w8lchsBRCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "from os import path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from dgl import batch\n",
        "from dgl.data.ppi import LegacyPPIDataset\n",
        "from dgl.nn.pytorch import GraphConv \n",
        "from sklearn.metrics import f1_score\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "from dgl.nn.pytorch import GATConv "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9OeA9CH0R66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dgl.nn.pytorch import GATConv "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo-2lEslEuCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class parser(object):\n",
        "  def __init__(self,mode='train',gpu=0,epochs=250,batch_size=2,num_heads=8,num_out_heads=1): \n",
        "    self.mode=mode\n",
        "    self.gpu=gpu \n",
        "    self.epochs=epochs\n",
        "    self.batch_size=batch_size\n",
        "    self.num_out_heads=num_out_heads\n",
        "    self.num_heads=num_heads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Bq9sZSBY0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_STATE_FILE = \"model_state.pth\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXTXoRl92IBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dgl.nn.pytorch import  GATConv\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self,g,n_layers,input_size,hidden_size,output_size,heads,nonlinearity,feat_drop=0,attn_drop=0.1,negative_slope=0.2,residual=False):\n",
        "        super(GAT, self).__init__()\n",
        "        self.g = g\n",
        "        self.n_layers = n_layers\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.activation = nonlinearity\n",
        "        # input projection \n",
        "        self.layers.append(GATConv(\n",
        "            input_size, hidden_size, heads[0],\n",
        "            feat_drop, attn_drop, negative_slope, False, self.activation))\n",
        "        # hidden layers with Residual\n",
        "        for l in range(1, n_layers):\n",
        "            # due to multi-head, the in_dim = num_hidden * num_heads\n",
        "            self.layers.append(GATConv(\n",
        "                hidden_size * heads[l-1], hidden_size, heads[l],\n",
        "                feat_drop, attn_drop, negative_slope, residual, self.activation))\n",
        "        # output projection, with Residual\n",
        "        self.layers.append(GATConv(\n",
        "            hidden_size * heads[-2], output_size, heads[-1],\n",
        "            feat_drop, attn_drop, negative_slope, residual, None))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = inputs\n",
        "        for l in range(self.n_layers):\n",
        "          #Concat heads output for intermediary layers \n",
        "          outputs = self.layers[l](self.g, outputs).flatten(1)\n",
        "        # We use mean of heads for last Layer \n",
        "        logits = self.layers[-1](self.g, outputs).mean(1)\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xIZOvGZBbJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicGraphModel(nn.Module):\n",
        "    def __init__(self, g, n_layers, input_size, hidden_size, output_size, nonlinearity):\n",
        "        super().__init__()\n",
        "        self.g = g\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(GATConv(input_size, hidden_size,num_heads=3,activation=nonlinearity))\n",
        "        for i in range(n_layers - 1):\n",
        "            self.layers.append(GATConv(hidden_size, hidden_size,num_heads=3,activation=nonlinearity))\n",
        "        self.layers.append(GATConv(hidden_size, output_size,num_heads=3))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = inputs\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            outputs = layer(self.g, outputs)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6EafwQUEd9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loss_fcn, device, optimizer, train_dataloader, test_dataset,scheduler):\n",
        "    for epoch in range(args.epochs):\n",
        "        model.train() \n",
        "        losses = [] \n",
        "        for batch, data in enumerate(train_dataloader):\n",
        "            subgraph, features, labels = data\n",
        "            features = features.to(device)\n",
        "            labels = labels.to(device)\n",
        "            model.g = subgraph\n",
        "            for layer in model.layers:\n",
        "                layer.g = subgraph\n",
        "            logits = model(features.float())\n",
        "            loss = loss_fcn(logits, labels.float())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "        loss_data = np.array(losses).mean()\n",
        "        print(\"Epoch {:05d} | Loss: {:.4f}\".format(epoch + 1, loss_data))\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            scores = []\n",
        "            for batch, test_data in enumerate(test_dataset):\n",
        "                subgraph, features, labels = test_data\n",
        "                features = torch.tensor(features).to(device)\n",
        "                labels = torch.tensor(labels).to(device)\n",
        "                score, _ = evaluate(features.float(), model, subgraph, labels.float(), loss_fcn)\n",
        "                scores.append(score)\n",
        "            print(\"F1-Score: {:.4f} \".format(np.array(scores).mean()))\n",
        "        scheduler.step()\n",
        "def test(model, loss_fcn, device, test_dataloader):\n",
        "    test_scores = []\n",
        "    for batch, test_data in enumerate(test_dataloader):\n",
        "        subgraph, features, labels = test_data\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "        test_scores.append(evaluate(features, model, subgraph, labels.float(), loss_fcn)[0])\n",
        "    mean_scores = np.array(test_scores).mean()\n",
        "    print(\"F1-Score: {:.4f}\".format(np.array(test_scores).mean()))\n",
        "    return mean_scores\n",
        "\n",
        "\n",
        "def evaluate(features, model, subgraph, labels, loss_fcn):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        model.g = subgraph\n",
        "        for layer in model.layers:\n",
        "            layer.g = subgraph\n",
        "        output = model(features.float())\n",
        "        loss_data = loss_fcn(output, labels.float())\n",
        "        predict = np.where(output.data.cpu().numpy() >= 0.5, 1, 0)\n",
        "        score = f1_score(labels.data.cpu().numpy(), predict, average=\"micro\")\n",
        "        return score, loss_data.item()\n",
        "\n",
        "\n",
        "def collate_fn(sample):\n",
        "    graphs, features, labels = map(list, zip(*sample))\n",
        "    graph = batch(graphs)\n",
        "    features = torch.from_numpy(np.concatenate(features))\n",
        "    labels = torch.from_numpy(np.concatenate(labels))\n",
        "    return graph, features, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX-vKFLRGSWJ",
        "colab_type": "code",
        "outputId": "f4b78614-7e5a-42b0-9a1c-bd19d93e6416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "if torch.cuda.is_available() : \n",
        "  gpu=0 \n",
        "else : \n",
        "  gpu=-1 \n",
        "args=parser(gpu=gpu) \n",
        "\n",
        "# create the dataset \n",
        "train_dataset, test_dataset = LegacyPPIDataset(mode=\"train\"), LegacyPPIDataset(mode=\"test\")\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, collate_fn=collate_fn)\n",
        "n_features, n_classes = train_dataset.features.shape[1], train_dataset.labels.shape[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.dgl/ppi.zip from https://data.dgl.ai/dataset/ppi.zip...\n",
            "Extracting file to /root/.dgl/ppi\n",
            "Loading G...\n",
            "Loading G...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP7uqBmiNJMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args.num_heads=10\n",
        "args.num_out_heads=5\n",
        "args.epochs=500\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g50upnvo9LsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_layers=4\n",
        "heads = ([args.num_heads] * n_layers) + [args.num_out_heads] \n",
        "# create the model, loss function and optimizer \n",
        "device = torch.device(\"cpu\" if args.gpu < 0 else \"cuda:\" + str(args.gpu))\n",
        "model=GAT(g=train_dataset.graph,n_layers=n_layers,input_size=n_features,\n",
        "          feat_drop=0.,attn_drop=0.1,hidden_size=256,output_size=n_classes,\n",
        "          heads=heads,nonlinearity=F.elu,residual=True).to(device)\n",
        "          \n",
        "loss_fcn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "scheduler=lr_scheduler.StepLR(optimizer,step_size=300,gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKt93UH-n8f4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTubTdkuKUCS",
        "colab_type": "code",
        "outputId": "9820aa0e-30e2-442a-e139-12e15d9fe721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "# train and test\n",
        "if args.mode == \"train\":\n",
        "    model.train()\n",
        "    train(model , loss_fcn, device, optimizer, train_dataloader, test_dataset,scheduler)\n",
        "torch.save(model.state_dict(), MODEL_STATE_FILE)\n",
        "model.load_state_dict(torch.load(MODEL_STATE_FILE))\n",
        "test(model, loss_fcn, device, test_dataloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-eea259b5af86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_STATE_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_STATE_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-b0f7369abe0f>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, loss_fcn, device, test_dataloader)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mtest_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mmean_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1-Score: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b0f7369abe0f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(features, model, subgraph, labels, loss_fcn)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mloss_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-bee698144159>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0;31m#Concat heads output for intermediary layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# We use mean of heads for last Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/nn/pytorch/conv/gatconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# message passing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         graph.update_all(fn.u_mul_e('ft', 'a', 'm'),\n\u001b[0;32m--> 114\u001b[0;31m                          fn.sum('m', 'ft'))\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mrst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# residual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   2745\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 2747\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2749\u001b[0m     def prop_nodes(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1076\u001b[0m         self.ret.data = F.binary_reduce(\n\u001b[1;32m   1077\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m             lhs_data, rhs_data, self.out_size, lhs_map, rhs_map, out_map)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mbinary_reduce\u001b[0;34m(reducer, binary_op, graph, lhs, rhs, lhs_data, rhs_data, out_size, lhs_map, rhs_map, out_map)\u001b[0m\n\u001b[1;32m    374\u001b[0m     return BinaryReduce.apply(\n\u001b[1;32m    375\u001b[0m             \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             out_size, lhs_map, rhs_map, out_map)\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, binary_op, graph, lhs, rhs, lhs_data, rhs_data, out_data, out_size, lhs_map, rhs_map, out_map)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mbinary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs_data_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_data_nd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             out_data_nd, lhs_map[0], rhs_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mbinary_op_reduce\u001b[0;34m(reducer, op, G, A_target, B_target, A, B, out, A_rows, B_rows, out_rows)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         A_rows, B_rows, out_rows)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgEsUxFGt4hF",
        "colab_type": "code",
        "outputId": "a874d05a-b1f9-4fd3-9a35-39f1fcebb93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!python train_ppi.py --mode \"test\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading G...\n",
            "Loading G...\n",
            "F1-Score: 0.3914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGtlLut5L4ko",
        "colab_type": "code",
        "outputId": "9eb2ce11-f29a-4162-e876-b14b403768cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.eval()\n",
        "test(model, loss_fcn, device, test_dataloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score: 0.9923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9923130152235393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwcDJNzaldSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the model, loss function and optimizer\n",
        "device = torch.device(\"cpu\" if args.gpu < 0 else \"cuda:\" + str(args.gpu))\n",
        "n_layers=2\n",
        "model = BasicGraphModel(g=train_dataset.graph, n_layers=n_layers, input_size=n_features,\n",
        "                        hidden_size=256, output_size=n_classes, nonlinearity=F.elu).to(device)\n",
        "loss_fcn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuuW74YamncI",
        "colab_type": "code",
        "outputId": "18cbdb46-e692-47c5-dd95-234a48109bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "def make_dot(var, params):\n",
        "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
        "    \n",
        "    Blue nodes are the Variables that require grad, orange are Tensors\n",
        "    saved for backward in torch.autograd.Function\n",
        "    \n",
        "    Args:\n",
        "        var: output Variable\n",
        "        params: dict of (name, Variable) to add names to node that\n",
        "            require grad (TODO: make optional)\n",
        "    \"\"\"\n",
        "    param_map = {id(v): k for k, v in params.items()}\n",
        "    print(param_map)\n",
        "    \n",
        "    node_attr = dict(style='filled',\n",
        "                     shape='box',\n",
        "                     align='left',\n",
        "                     fontsize='12',\n",
        "                     ranksep='0.1',\n",
        "                     height='0.2')\n",
        "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
        "    seen = set()\n",
        "    \n",
        "    def size_to_str(size):\n",
        "        return '('+(', ').join(['%d'% v for v in size])+')'\n",
        "\n",
        "    def add_nodes(var):\n",
        "        if var not in seen:\n",
        "            if torch.is_tensor(var):\n",
        "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
        "            elif hasattr(var, 'variable'):\n",
        "                u = var.variable\n",
        "                node_name = '%s\\n %s' % (param_map.get(id(u)), size_to_str(u.size()))\n",
        "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
        "            else:\n",
        "                dot.node(str(id(var)), str(type(var).__name__))\n",
        "            seen.add(var)\n",
        "            if hasattr(var, 'next_functions'):\n",
        "                for u in var.next_functions:\n",
        "                    if u[0] is not None:\n",
        "                        dot.edge(str(id(u[0])), str(id(var)))\n",
        "                        add_nodes(u[0])\n",
        "            if hasattr(var, 'saved_tensors'):\n",
        "                for t in var.saved_tensors:\n",
        "                    dot.edge(str(id(t)), str(id(var)))\n",
        "                    add_nodes(t)\n",
        "    add_nodes(var.grad_fn)\n",
        "    return dot\n",
        "\n",
        "a,b,c=next(iter(train_dataloader))\n",
        "model.g = a\n",
        "for layer in model.layers:\n",
        "    layer.g = a\n",
        "y = model(b.float().to(device))\n",
        "g = make_dot(y, model.state_dict())\n",
        "g.view()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{140093222727040: 'layers.0.attn_l', 140093222710224: 'layers.0.attn_r', 140093222707632: 'layers.0.fc.weight', 140093222752328: 'layers.1.attn_l', 140093222752400: 'layers.1.attn_r', 140093222752544: 'layers.1.fc.weight', 140093222753264: 'layers.1.res_fc.weight', 140093222753408: 'layers.2.attn_l', 140093222753480: 'layers.2.attn_r', 140093222753624: 'layers.2.fc.weight', 140093222754344: 'layers.2.res_fc.weight', 140093222754488: 'layers.3.attn_l', 140093222754560: 'layers.3.attn_r', 140093222754704: 'layers.3.fc.weight', 140093222755424: 'layers.3.res_fc.weight', 140093222755568: 'layers.4.attn_l', 140093222755640: 'layers.4.attn_r', 140093222755784: 'layers.4.fc.weight', 140093222744280: 'layers.4.res_fc.weight'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Digraph.gv.pdf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}