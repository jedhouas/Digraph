{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "nlp_project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jedhouas/Digraph/blob/master/nlp_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua15eE4YgvPg",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning for NLP - Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UucYEZdQgvPk",
        "colab_type": "text"
      },
      "source": [
        "RULES:\n",
        "\n",
        "* Do not create any additional cell\n",
        "\n",
        "* Fill in the blanks\n",
        "\n",
        "* All cells should be runnable (modulo trivial compatibility bugs that we'd fix)\n",
        "\n",
        "* 4 / 20 points will be allocated to the clarity of your code\n",
        "\n",
        "* Efficient code will have a bonus\n",
        "\n",
        "DELIVERABLE:\n",
        "\n",
        "* the pdf with your answers\n",
        "* this notebook\n",
        "* the predictions of the SST test set\n",
        "\n",
        "DO NOT INCLUDE THE DATASETS IN THE DELIVERABLE.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "wflu5lX7gvPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python 3.6 or above is required\n",
        "from collections import defaultdict\n",
        "import gzip\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from urllib.request import urlretrieve\n",
        "import re\n",
        "import numpy.linalg as linalg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vBALXtMgvQC",
        "colab_type": "code",
        "outputId": "1705a463-a643-4a50-974b-e7a1be590134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "PATH_TO_DATA = Path('data/')\n",
        "# Download word vectors, might take a few minutes and about ~3GB of storage space\n",
        "en_embeddings_path = PATH_TO_DATA / 'cc.en.300.vec.gz'\n",
        "if not en_embeddings_path.exists():\n",
        "    urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz', en_embeddings_path)\n",
        "fr_embeddings_path = PATH_TO_DATA / 'cc.fr.300.vec.gz'\n",
        "if not fr_embeddings_path.exists():\n",
        "    urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.vec.gz', fr_embeddings_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7dce42f2716a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0men_embeddings_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPATH_TO_DATA\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'cc.en.300.vec.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0men_embeddings_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_embeddings_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfr_embeddings_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPATH_TO_DATA\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'cc.fr.300.vec.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfr_embeddings_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Handle temporary file setup.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mtfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mtfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/cc.en.300.vec.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aeNVIoFgvQM",
        "colab_type": "text"
      },
      "source": [
        "# 1) Monolingual (English) word embeddings "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDwItYYngvQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Word2Vec():\n",
        "\n",
        "    def __init__(self, filepath, vocab_size=50000):\n",
        "        self.words, self.embeddings = self.load_wordvec(filepath, vocab_size)\n",
        "        # Mappings for O(1) retrieval:\n",
        "        self.word2id = {word: idx for idx, word in enumerate(self.words)}\n",
        "        self.id2word = {idx: word for idx, word in enumerate(self.words)}\n",
        "    \n",
        "    def load_wordvec(self, filepath, vocab_size):\n",
        "        assert str(filepath).endswith('.gz')\n",
        "        words = []\n",
        "        embeddings = []\n",
        "        with gzip.open(filepath, 'rt') as f:  # Read compressed file directly\n",
        "            next(f)  # Skip header\n",
        "            for i, line in enumerate(f):\n",
        "                word, vec = line.split(' ', 1)\n",
        "                words.append(word)\n",
        "                embeddings.append(np.fromstring(vec, sep=' '))\n",
        "                if i == (vocab_size - 1):\n",
        "                    break\n",
        "        print('Loaded %s pretrained word vectors' % (len(words)))\n",
        "        return words, np.vstack(embeddings)\n",
        "    \n",
        "    def encode(self, word):\n",
        "        # Returns the 1D embedding of a given word\n",
        "        # Returns 0 if words doesn't exist in self.words\n",
        "        if word in self.words:\n",
        "            return(self.embeddings[self.word2id[word]])\n",
        "        else:\n",
        "            return(np.zeros(300))\n",
        "        raise NotImplementedError('Fill in the blank')\n",
        "    \n",
        "    def score(self, word1, word2):\n",
        "        # Return the cosine similarity: use np.dot & np.linalg.norm\n",
        "        vec1 = self.encode(word1)\n",
        "        vec2 = self.encode(word2)\n",
        "        return(np.dot(vec1.T,vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2)))\n",
        "        raise NotImplementedError('Fill in the blank')\n",
        "    \n",
        "    def most_similar(self, word, k=5):\n",
        "        # Returns the k most similar words: self.score & np.argsort \n",
        "        scores=[self.score(word,vocab) for vocab in self.words]\n",
        "        sorted_scores=np.flip(np.argsort(scores,axis=None))\n",
        "        return [self.id2word[idx] for idx in sorted_scores[1:k+1]] # Not including the biggest score (argscore = 0) because it should be the word itself\n",
        "        raise NotImplementedError('Fill in the blank')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ONJk_ItggvQx",
        "colab_type": "code",
        "outputId": "d7677f3c-2a2d-4fa5-a095-8fe0fca8a09d",
        "colab": {}
      },
      "source": [
        "word2vec = Word2Vec(en_embeddings_path, vocab_size=50000)\n",
        "\n",
        "# You will be evaluated on the output of the following:\n",
        "for word1, word2 in zip(('cat', 'cat', 'cat', 'Paris', 'Paris', 'Paris', 'Paris'), ('tree', 'dog', 'pet', 'France', 'Germany', 'baguette', 'donut')):\n",
        "    print(word1, word2, word2vec.score(word1, word2))\n",
        "for word in ['cat', 'dog', 'dogs', 'Paris', 'Germany']:\n",
        "    print(word2vec.most_similar(word))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 50000 pretrained word vectors\n",
            "cat tree 0.26449754661654756\n",
            "cat dog 0.7078641298542564\n",
            "cat pet 0.6753313359976382\n",
            "Paris France 0.6892958925806543\n",
            "Paris Germany 0.4051242286737549\n",
            "Paris baguette 0.29399958277802224\n",
            "Paris donut -0.006588507552348003\n",
            "['cats', 'kitty', 'kitten', 'feline', 'dog']\n",
            "['dogs', 'puppy', 'pup', 'canine', 'pet']\n",
            "['dog', 'cats', 'puppies', 'Dogs', 'pets']\n",
            "['France', 'Parisian', 'Marseille', 'Brussels', 'Strasbourg']\n",
            "['Austria', 'Europe', 'Berlin', 'Hamburg', 'Bavaria']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "H_ufZT-3gvQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BagOfWords():\n",
        "    \n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "    \n",
        "    def build_idf(self, sentences):\n",
        "        # build the idf dictionary: associate each word to its idf value\n",
        "        d = defaultdict(float)\n",
        "        for sentence in sentences:\n",
        "            words=np.unique([word for word in re.sub(r'\\W+', ' ', sentence).split()])\n",
        "            for word in words:\n",
        "                d[word]+=1\n",
        "        D=len(sentences)\n",
        "        idf={k:np.log(D/v) for k,v in d.items()}\n",
        "        return idf\n",
        "        raise NotImplementedError('Fill in the blank')\n",
        "    \n",
        "    def encode(self, sentence, idf=None):\n",
        "        # Takes a sentence as input, returns the sentence embedding\n",
        "        w = np.unique([word for word in re.sub(r'\\W+', ' ', sentence).split()])\n",
        "        res = np.zeros(300)\n",
        "        s = 0\n",
        "        if idf is None:\n",
        "            # mean of word vectors\n",
        "            for word in w:\n",
        "                if word in self.word2vec.words:\n",
        "                    res = res + self.word2vec.encode(word)\n",
        "                    s = s + 1\n",
        "            if s == 0:\n",
        "                return(res)\n",
        "            else:\n",
        "                return((1/s)*res)\n",
        "            raise NotImplementedError('Fill in the blank')\n",
        "        else:\n",
        "            # idf-weighted mean of word vectors\n",
        "            for word in w:\n",
        "                if (word in self.word2vec.words) and (word in idf.keys()):\n",
        "                    res = res + idf[word]*self.word2vec.encode(word)\n",
        "                    s = s + idf[word]\n",
        "            if s == 0:\n",
        "                return(res)\n",
        "            else:\n",
        "                return((1/s)*res)\n",
        "            raise NotImplementedError('Fill in the blank')\n",
        "\n",
        "    def score(self, sentence1, sentence2, idf=None):\n",
        "        # cosine similarity: use np.dot & np.linalg.norm\n",
        "        vec1 = self.encode(sentence1)\n",
        "        vec2 = self.encode(sentence2)\n",
        "        return(np.dot(vec1,vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2)))\n",
        "        raise NotImplementedError('Fill in the blank')\n",
        "    \n",
        "    def most_similar(self, sentence, sentences, idf=None, k=5):\n",
        "        # Return most similar sentences\n",
        "        scores=[self.score(sentence, sent, idf) for sent in sentences]\n",
        "        sorted_scores=np.flip(np.argsort(scores,axis=None))\n",
        "        return [sentences[idx] for idx in sorted_scores[0:k]]\n",
        "        raise NotImplementedError('Fill in the blank')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ThSbMmyVgvRP",
        "colab_type": "code",
        "outputId": "210432f8-a6c1-4a53-aa52-48a9492248c0",
        "colab": {}
      },
      "source": [
        "word2vec = Word2Vec(en_embeddings_path, vocab_size=50000)\n",
        "sentence2vec = BagOfWords(word2vec)\n",
        "\n",
        "# Load sentences in \"PATH_TO_DATA/sentences.txt\"\n",
        "filepath = PATH_TO_DATA / 'sentences.txt'\n",
        "with open(filepath, 'r') as f:\n",
        "    sentences = [line.strip('\\n') for line in f]\n",
        "\n",
        "\n",
        "# You will be evaluated on the output of the following:\n",
        "print('\\n\\tAverage of word embeddings')\n",
        "sentence1 = sentences[7]\n",
        "sentence2 = sentences[13]\n",
        "print(sentence1)\n",
        "print(sentence2)\n",
        "print(sentence2vec.score(sentence1, sentence2))\n",
        "sentence = sentences[10]\n",
        "similar_sentences = sentence2vec.most_similar(sentence, sentences)  # BagOfWords-mean\n",
        "print(sentence)\n",
        "for i, sentence in enumerate(similar_sentences):\n",
        "    print(str(i+1) + ')', sentence)\n",
        "\n",
        "# Build idf scores for each word\n",
        "idf = sentence2vec.build_idf(sentences)\n",
        "\n",
        "print('\\n\\tidf weighted average of word embeddings')\n",
        "print(sentence1)\n",
        "print(sentence2)\n",
        "print(sentence2vec.score(sentence1, sentence2, idf))\n",
        "similar_sentences = sentence2vec.most_similar(sentence, sentences, idf)  # BagOfWords-idf\n",
        "print(sentence)\n",
        "for i, sentence in enumerate(similar_sentences):\n",
        "    print(str(i+1) + ')', sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 50000 pretrained word vectors\n",
            "\n",
            "\tAverage of word embeddings\n",
            "1 man singing and 1 man playing a saxophone in a concert . \n",
            "10 people venture out to go crosscountry skiing . \n",
            "0.6545625066602266\n",
            "1 smiling african american boy . \n",
            "1) 1 smiling african american boy . \n",
            "2) 2 woman dancing while pointing . \n",
            "3) 5 women and 1 man are smiling for the camera . \n",
            "4) 3 males and 1 woman enjoying a sporting event \n",
            "5) 2 chinese people wearing traditional clothes \n",
            "\n",
            "\tidf weighted average of word embeddings\n",
            "1 man singing and 1 man playing a saxophone in a concert . \n",
            "10 people venture out to go crosscountry skiing . \n",
            "0.6545625066602266\n",
            "2 chinese people wearing traditional clothes \n",
            "1) 2 chinese people wearing traditional clothes \n",
            "2) 2 woman dancing while pointing . \n",
            "3) 3 security woman with sunglasses walking \n",
            "4) 2 people fighting with training swords \n",
            "5) 2 female babies eating chips . \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfrRHaDKgvRc",
        "colab_type": "text"
      },
      "source": [
        "# 2) Multilingual (English-French) word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JNJ5cKXgvRd",
        "colab_type": "text"
      },
      "source": [
        "Let's consider a bilingual dictionary of size V_a (e.g French-English).\n",
        "\n",
        "Let's define **X** and **Y** the **French** and **English** matrices.\n",
        "\n",
        "They contain the embeddings associated to the words in the bilingual dictionary.\n",
        "\n",
        "We want to find a **mapping W** that will project the source word space (e.g French) to the target word space (e.g English).\n",
        "\n",
        "Procrustes : **W\\* = argmin || W.X - Y ||  s.t  W^T.W = Id**\n",
        "has a closed form solution:\n",
        "**W = U.V^T  where  U.Sig.V^T = SVD(Y.X^T)**\n",
        "\n",
        "In what follows, you are asked to: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN86B7bIgvRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultilingualWordAligner:\n",
        "    \n",
        "    def __init__(self, fr_word2vec, en_word2vec):\n",
        "        self.fr_word2vec = fr_word2vec\n",
        "        self.en_word2vec = en_word2vec\n",
        "        self.aligned_fr_embeddings = self.get_aligned_fr_embeddings()\n",
        "        \n",
        "    def get_aligned_fr_embeddings(self):\n",
        "        # 1 - Get words that appear in both vocabs (= identical character strings)\n",
        "        #     Use it to create the matrix X (emb_dim, vocab_size) and Y (emb_dim, vocab_size) (of embeddings for these words)\n",
        "        commun_words = list(set(self.fr_word2vec.words).intersection(self.en_word2vec.words))\n",
        "        X = np.vstack(self.fr_word2vec.encode(word) for word in commun_words).T\n",
        "        Y = np.vstack(self.en_word2vec.encode(word) for word in commun_words).T\n",
        "        #raise NotImplementedError('Fill in the blank')\n",
        "        assert X.shape[0] == 300 and Y.shape[0] == 300\n",
        "        \n",
        "        # 2 - Solve the Procrustes using the numpy package and: np.linalg.svd() and get the optimal W\n",
        "        #     Now self.fr_word2vec.embeddings * W.transpose() is in the same space as en_word2vec.embeddings\n",
        "        U, S, VT = np.linalg.svd(Y.dot(X.T))\n",
        "        W = U.dot(VT)\n",
        "        #raise NotImplementedError('Fill in the blank')\n",
        "        assert W.shape == (300, 300)\n",
        "        return np.matmul(fr_word2vec.embeddings, W.transpose())\n",
        "        \n",
        "    def get_closest_english_words(self, fr_word, k=3):\n",
        "        # 3 - Return the top k English nearest neighbors to the input French word\n",
        "        fr_emb = self.get_aligned_fr_embeddings()[self.fr_word2vec.word2id[fr_word]]\n",
        "        scores=[np.dot(fr_emb.T,en_emb)/(np.linalg.norm(fr_emb)*np.linalg.norm(en_emb)) for en_emb in self.en_word2vec.embeddings]\n",
        "        sorted_scores=np.flip(np.argsort(scores,axis=None))\n",
        "        return [self.en_word2vec.id2word[idx] for idx in sorted_scores[0:k]]\n",
        "        raise NotImplementedError('Fill in the blank')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YznzTJR-gvRi",
        "colab_type": "code",
        "outputId": "716fad8f-04e7-4761-9161-f17fdafca51d",
        "colab": {}
      },
      "source": [
        "fr_word2vec = Word2Vec(fr_embeddings_path, vocab_size=50000)\n",
        "en_word2vec = Word2Vec(en_embeddings_path, vocab_size=50000)\n",
        "multilingual_word_aligner = MultilingualWordAligner(fr_word2vec, en_word2vec)\n",
        "\n",
        "# You will be evaluated on the output of the following:\n",
        "fr_words = ['chat', 'chien', 'voiture', 'zut']\n",
        "k = 3\n",
        "for fr_word in fr_words:\n",
        "    print('-' * 10)\n",
        "    print(f'fr: \"{fr_word}\"')\n",
        "    en_words = multilingual_word_aligner.get_closest_english_words(fr_word, k=3)\n",
        "    for en_word in en_words:\n",
        "        print(f'en: \"{en_word}\"')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 50000 pretrained word vectors\n",
            "Loaded 50000 pretrained word vectors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/jedhouas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if sys.path[0] == '':\n",
            "/Users/jedhouas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------\n",
            "fr: \"chat\"\n",
            "en: \"cat\"\n",
            "en: \"kitten\"\n",
            "en: \"kitty\"\n",
            "----------\n",
            "fr: \"chien\"\n",
            "en: \"dog\"\n",
            "en: \"cat\"\n",
            "en: \"pet\"\n",
            "----------\n",
            "fr: \"voiture\"\n",
            "en: \"car\"\n",
            "en: \"vehicle\"\n",
            "en: \"automobile\"\n",
            "----------\n",
            "fr: \"zut\"\n",
            "en: \"oops\"\n",
            "en: \"Ah\"\n",
            "en: \"ah\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYwdV-sBgvR3",
        "colab_type": "text"
      },
      "source": [
        "If you want to dive deeper on this subject: https://github.com/facebookresearch/MUSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogj7o1-hgvR7",
        "colab_type": "text"
      },
      "source": [
        "# 3) Sentence classification with BoV and scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3D_Jbf_gvSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1 - Load train/dev/test of Stanford Sentiment TreeBank (SST)\n",
        "#     (https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)\n",
        "sst_train_path = PATH_TO_DATA / 'SST/stsa.fine.train'\n",
        "sst_dev_path = PATH_TO_DATA / 'SST/stsa.fine.dev'\n",
        "sst_test_path = PATH_TO_DATA / 'SST/stsa.fine.test.X'\n",
        "with open(sst_train_path, 'r') as f:\n",
        "    sst_train_sentences = [line.strip('\\n') for line in f]\n",
        "with open(sst_dev_path, 'r') as f:\n",
        "    sst_dev_sentences = [line.strip('\\n') for line in f]\n",
        "with open(sst_test_path, 'r') as f:\n",
        "    sst_test_sentences = [line.strip('\\n') for line in f]\n",
        "\n",
        "def read_raw(raw):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for line in raw:\n",
        "        label, sentence = line.split(\" \", 1)\n",
        "        sentences.append(sentence)\n",
        "        labels.append(int(label))\n",
        "    return sentences, labels\n",
        "\n",
        "f = open(PATH_TO_DATA/ 'SST/stsa.fine.train')\n",
        "sst_train_raw = f.readlines()\n",
        "f.close()\n",
        "f = open(PATH_TO_DATA/ 'SST/stsa.fine.dev')\n",
        "sst_dev_raw = f.readlines()\n",
        "f.close()\n",
        "f = open(PATH_TO_DATA/ 'SST/stsa.fine.test.X')\n",
        "sst_test = f.readlines()\n",
        "f.close()\n",
        "\n",
        "sst_train, label_train = read_raw(sst_train_raw)\n",
        "sst_dev, label_dev = read_raw(sst_dev_raw)\n",
        "\n",
        "sst_train_sentences = [x.strip('\\n') for x in sst_train]\n",
        "sst_dev_sentences = [x.strip('\\n') for x in sst_dev]\n",
        "sst_test_sentences = [x.strip('\\n') for x in sst_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhmr9EFKgvSZ",
        "colab_type": "code",
        "outputId": "f1d48dcf-6483-46c0-fded-9558e2ab96ff",
        "colab": {}
      },
      "source": [
        "# 2 - Encode sentences with the BoV model above\n",
        "word2vec = Word2Vec(en_embeddings_path, vocab_size=50000)\n",
        "sentence2vec = BagOfWords(word2vec)\n",
        "bov_train_idf = []\n",
        "bov_dev_idf = []\n",
        "bov_test_idf = []\n",
        "bov_train_mean = []\n",
        "bov_dev_mean = []\n",
        "bov_test_mean = []\n",
        "idf_sst = sentence2vec.build_idf(sst_train_sentences + sst_dev_sentences + sst_test_sentences)\n",
        "for sent in sst_train_sentences:\n",
        "    bov_train_idf.append(sentence2vec.encode(sent, idf_sst))\n",
        "for sent in sst_dev_sentences:\n",
        "    bov_dev_idf.append(sentence2vec.encode(sent, idf_sst))\n",
        "for sent in sst_test_sentences:\n",
        "    bov_test_idf.append(sentence2vec.encode(sent, idf_sst))\n",
        "for sent in sst_train_sentences:\n",
        "    bov_train_mean.append(sentence2vec.encode(sent, idf=None))\n",
        "for sent in sst_dev_sentences:\n",
        "    bov_dev_mean.append(sentence2vec.encode(sent, idf=None))\n",
        "for sent in sst_test_sentences:\n",
        "    bov_test_mean.append(sentence2vec.encode(sent, idf=None))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 50000 pretrained word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRtpsyBxgvSg",
        "colab_type": "code",
        "outputId": "92997155-206c-4c50-beee-06925881e8fa",
        "colab": {}
      },
      "source": [
        "# 3 - Learn Logistic Regression on top of sentence embeddings using scikit-learn\n",
        "#     (consider tuning the L2 regularization on the dev set)\n",
        "#     In the paper, the accuracy for average of word vectors is 32.7%\n",
        "#     (VecAvg, table 1, https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)\n",
        "\n",
        "# TYPE CODE HERE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameter selection without idf\n",
        "Cs = np.linspace(1e-3, 8, 10)\n",
        "accuracy_mean = []\n",
        "for C in Cs:\n",
        "    classifier = LogisticRegression(penalty=\"l2\", C=C, solver=\"liblinear\", multi_class='ovr', tol=1e-6)\n",
        "    classifier.fit(bov_train_mean, label_train)\n",
        "    prediction = classifier.predict(bov_dev_mean)\n",
        "    accuracy = np.mean(prediction == label_dev)\n",
        "    accuracy_mean.append(accuracy)\n",
        "\n",
        "# Parameter selection with idf\n",
        "accuracy_idf = []\n",
        "for C in Cs:\n",
        "    classifier = LogisticRegression(penalty=\"l2\", C=C, solver=\"liblinear\", multi_class='ovr', tol=1e-6)\n",
        "    classifier.fit(bov_train_idf, label_train)\n",
        "    prediction = classifier.predict(bov_dev_idf)\n",
        "    accuracy = np.mean(prediction == label_dev)\n",
        "    accuracy_idf.append(accuracy)\n",
        "\n",
        "C_mean = Cs[np.argmax(accuracy_mean)]\n",
        "C_idf = Cs[np.argmax(accuracy_mean)]\n",
        "\n",
        "print(\"Best BoV-mean accuracy : {}\".format(max(accuracy_mean)))\n",
        "print(\"Best BoV-idf accuracy : {}\".format(max(accuracy_idf)))\n",
        "plt.plot(accuracy_mean, label=\"BoV-mean\")\n",
        "plt.plot(accuracy_idf, label=\"BoV-idf\")\n",
        "plt.xlabel(\"Regularization parameter\", fontsize=12)\n",
        "plt.ylabel(\"Dev prediction accuracy\", fontsize=12)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best BoV-mean accuracy : 0.4087193460490463\n",
            "Best BoV-idf accuracy : 0.4178019981834696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj-nRSAmgvSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4 - Produce 2210 predictions for the test set (in the same order). One line = one prediction (=0,1,2,3,4).\n",
        "#     Attach the output file \"logreg_bov_y_test_sst.txt\" to your deliverable.\n",
        "#     You will be evaluated on the results of the test set.\n",
        "\n",
        "# TYPE CODE HERE\n",
        "best_classifier = LogisticRegression(penalty=\"l2\", C=C_mean, solver=\"liblinear\", multi_class='ovr', tol=1e-6)\n",
        "best_classifier.fit(bov_train_idf, label_train)\n",
        "prediction_test = best_classifier.predict(bov_test_mean)\n",
        "text_to_write = \"\\n\".join(prediction_test.astype(str))\n",
        "f = open(\"logreg_bov_y_test_sst.txt\", \"w\")\n",
        "f.write(text_to_write)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhoVInTzgvSv",
        "colab_type": "code",
        "outputId": "f8f6b3ca-3f71-416b-d610-f0d7e671c3a7",
        "colab": {}
      },
      "source": [
        "# BONUS!\n",
        "# 5 - Try to improve performance with another classifier\n",
        "#     Attach the output file \"XXX_bov_y_test_sst.txt\" to your deliverable (where XXX = the name of the classifier)\n",
        "\n",
        "# TYPE CODE HERE\n",
        "import xgboost as xgb\n",
        "\n",
        "classifier_xgb_mean = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05, n_jobs=4)\n",
        "classifier_xgb_mean.fit(np.vstack(bov_train_mean), label_train)\n",
        "prediction_mean = classifier_xgb_mean.predict(bov_dev_mean)\n",
        "accuracy_mean = np.mean(prediction_mean == label_dev)\n",
        "print(\"XGBoost bov-mean accuracy : {}\".format(accuracy_mean))\n",
        "\n",
        "classifier_xgb_idf = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05, n_jobs=4)\n",
        "classifier_xgb_idf.fit(np.vstack(bov_train_idf), label_train)\n",
        "prediction_idf = classifier_xgb_idf.predict(bov_dev_idf)\n",
        "accuracy_idf = np.mean(prediction_idf == label_dev)\n",
        "print(\"XGBoost bov-idf accuracy : {}\".format(accuracy_idf))\n",
        "\n",
        "# We take bov-mean, which is better\n",
        "prediction_test = classifier_xgb_mean.predict(bov_test_mean)\n",
        "text_to_write = \"\\n\".join(prediction_test.astype(str))\n",
        "f = open(\"xgb_bov_y_test_sst.txt\", \"w\")\n",
        "f.write(text_to_write)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/jedhouas/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "XGBoost bov-mean accuracy : 0.3887375113533152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/jedhouas/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "XGBoost bov-idf accuracy : 0.3960036330608538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/jedhouas/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt7VIgUmgvSz",
        "colab_type": "text"
      },
      "source": [
        "# 4) Sentence classification with LSTMs in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnmJzHHqgvS0",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 - Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "uboqP19ZgvS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.utils as utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gyYz8tdgvS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1 - Using the same dataset, transform text to integers using tf.keras.preprocessing.text.one_hot function\n",
        "#     https://keras.io/preprocessing/text/\n",
        "\n",
        "# TYPE CODE HERE\n",
        "def one_hot_array(array):\n",
        "    res = []\n",
        "    for sentence in array:\n",
        "        res.append(tf.keras.preprocessing.text.one_hot(sentence, n=50000))\n",
        "    return res\n",
        "\n",
        "x_train = one_hot_array(sst_train_sentences)\n",
        "x_dev = one_hot_array(sst_dev_sentences)\n",
        "x_test = one_hot_array(sst_test_sentences)\n",
        "y_train = utils.to_categorical(label_train)\n",
        "y_dev = utils.to_categorical(label_dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1SU_093gvS5",
        "colab_type": "text"
      },
      "source": [
        "**Padding input data**\n",
        "\n",
        "Models in Keras (and elsewhere) take batches of sentences of the same length as input. It is because Deep Learning framework have been designed to handle well Tensors, which are particularly suited for fast computation on the GPU.\n",
        "\n",
        "Since sentences have different sizes, we \"pad\" them. That is, we add dummy \"padding\" tokens so that they all have the same length.\n",
        "\n",
        "The input to a Keras model thus has this size : (batchsize, maxseqlen) where maxseqlen is the maximum length of a sentence in the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrWgOnoogvS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2 - Pad your sequences using tf.keras.preprocessing.sequence.pad_sequences\n",
        "#     https://keras.io/preprocessing/sequence/\n",
        "\n",
        "# TYPE CODE HERE\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=52)\n",
        "x_dev = tf.keras.preprocessing.sequence.pad_sequences(x_dev, maxlen=52)\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=52)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR5peKkqgvS8",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 - Design and train your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUO4AbsDgvS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3 - Design your encoder + classifier using tensorflow.keras.layers\n",
        "#     In Keras, Torch and other deep learning framework, we create a \"container\" which is the Sequential() module.\n",
        "#     Then we add components to this container : the lookup-table, the LSTM, the classifier etc.\n",
        "#     All of these components are contained in the Sequential() and are trained together.\n",
        "#     Note that the embedding layer is initialized randomly and does not take advantage of pre-trained word embeddings.\n",
        "\n",
        "\n",
        "# ADAPT CODE BELOW\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Activation\n",
        "\n",
        "embed_dim  = 300  # word embedding dimension\n",
        "nhid       = 70  # number of hidden units in the LSTM\n",
        "vocab_size = 50000  # size of the vocabulary\n",
        "n_classes  = 5\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embed_dim))\n",
        "model.add(LSTM(nhid, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(n_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9kSxaVdOgvTT",
        "colab_type": "code",
        "outputId": "bd692c42-8fbb-42b0-ba90-49381b6cbf3d",
        "colab": {}
      },
      "source": [
        "# 4 - Define your loss/optimizer/metrics\n",
        "\n",
        "# MODIFY CODE BELOW\n",
        "\n",
        "loss_classif     =  'categorical_crossentropy' # find the right loss for multi-class classification\n",
        "optimizer        =  'adagrad' # find the right optimizer\n",
        "metrics_classif  =  ['accuracy']\n",
        "\n",
        "# Observe how easy (but blackboxed) this is in Keras\n",
        "model.compile(loss=loss_classif,\n",
        "              optimizer=optimizer,\n",
        "              metrics=metrics_classif)\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 300)         15000000  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 70)                103880    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 355       \n",
            "=================================================================\n",
            "Total params: 15,104,235\n",
            "Trainable params: 15,104,235\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrDrbYwxgvTb",
        "colab_type": "code",
        "outputId": "f6dd7a0e-7da6-4a46-d54e-782feb873439",
        "colab": {}
      },
      "source": [
        "# 5 - Train your model and find the best hyperparameters for your dev set\n",
        "#     you will be evaluated on the quality of your predictions on the test set\n",
        "#     Keras expects y_train and y_dev to be one-hot encodings of the labels, i.e. with shape=(n_samples, 5)\n",
        "\n",
        "\n",
        "# ADAPT CODE BELOW\n",
        "bs = 64\n",
        "n_epochs = 7\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=bs, nb_epoch=n_epochs, validation_data=(x_dev, y_dev))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "Train on 8544 samples, validate on 1101 samples\n",
            "Epoch 1/7\n",
            "8544/8544 [==============================] - 111s 13ms/sample - loss: 1.5805 - accuracy: 0.2827 - val_loss: 1.5707 - val_accuracy: 0.2879\n",
            "Epoch 2/7\n",
            "8544/8544 [==============================] - 89s 10ms/sample - loss: 1.5567 - accuracy: 0.3249 - val_loss: 1.5641 - val_accuracy: 0.2916\n",
            "Epoch 3/7\n",
            "5568/8544 [==================>...........] - ETA: 22s - loss: 1.5452 - accuracy: 0.3488"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7389af680e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vkSY3aRgvTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 6 - Generate your predictions on the test set using model.predict(x_test)\n",
        "#     https://keras.io/models/model/\n",
        "#     Log your predictions in a file (one line = one integer: 0,1,2,3,4)\n",
        "#     Attach the output file \"logreg_lstm_y_test_sst.txt\" to your deliverable.\n",
        "\n",
        "# TYPE CODE HERE\n",
        "y_test_pred = model.predict(x_test)\n",
        "y_test_pred = y_test_pred.argmax(axis=1)\n",
        "text_to_write = \"\\n\".join(y_test_pred.astype(str))\n",
        "f = open(\"logreg_lstm_y_test_sst.txt\", \"w\")\n",
        "f.write(text_to_write)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxL8bZlzgvTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "X1 = history.history[\"accuracy\"]\n",
        "X2 = history.history[\"val_accuracy\"]\n",
        "plt.plot(X1, label=\"Train accuracy\")\n",
        "plt.plot(X2, label=\"Dev accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIgXe1GhgvTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Dev accuracy\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history[\"loss\"], label=\"Train loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Dev loss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtbCVS22gvTp",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 - innovate !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPeKzKcHgvTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7 - Open question: find a model that is better on your dev set\n",
        "#     (e.g: use a 1D ConvNet, use a better classifier, pretrain your lookup tables ..)\n",
        "#     you will get point if the results on the test set are better: be careful of not overfitting your dev set too much..\n",
        "#     Attach the output file \"XXX_XXX_y_test_sst.txt\" to your deliverable.\n",
        "\n",
        "# TYPE CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}